{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 1: Importing Libraries and Data</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#statmodel libraries\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads = pd.read_csv(\"Leads.csv\")\n",
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 2: Data Understanding and Inspection</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_leads.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 3: Data Cleaning</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_select_value = [col for col in df_leads.columns if len(df_leads[col].isin(['Select']).unique())>1]\n",
    "print(cols_with_select_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads = df_leads.replace('Select', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_select_value = [col for col in df_leads.columns if len(df_leads[col].isin(['Select']).unique())>1]\n",
    "print(cols_with_select_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(df_leads.isna().mean()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropNullColumns(data ,percentage=40):\n",
    "    \n",
    "    missing_perc = 100*(data.isna().mean()).sort_values(ascending=False)\n",
    "    col_to_drop = missing_perc[missing_perc>=percentage].index.to_list()\n",
    "    print(\"Total columns dropped: \",len(col_to_drop),\"\\n\")\n",
    "    print(\"List of columns dropped : \" , col_to_drop,\"\\n\")\n",
    "    print(\"Shape before dropping columns: \",data.shape)\n",
    "    \n",
    "    data.drop(labels=col_to_drop,axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Shape after dropping columns: \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropNullColumns(df_leads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(df_leads.isna().mean()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the selected columns\n",
    "\n",
    "categorical_cols = df_leads.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "print(categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsList= [\"City\",\"Specialization\",\"Tags\",'What matters most to you in choosing a course',\n",
    "              'What is your current occupation','Country','Last Activity','Lead Source']\n",
    "\n",
    "for i in columnsList:\n",
    "        perc=100*df_leads[i].value_counts(normalize=True)\n",
    "        print(\"value_counts % for :\",i,\"\\n\")\n",
    "        print(perc,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Columns\n",
    "print(\"Before Drop\",df_leads.shape)\n",
    "df_leads.drop(['City','Tags','Country','What matters most to you in choosing a course'],axis=1,inplace=True)\n",
    "print(\"After Drop\",df_leads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values={'Specialization':'Others','Lead Source':'Google','Last Activity':'Email Opened',\n",
    "               'What is your current occupation':'Unemployed'}\n",
    "df_leads=df_leads.fillna(value=missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re Checking the percentage of null values for remaining columns\n",
    "\n",
    "round(((df_leads.isnull().sum()/df_leads.shape[0])*100),2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalVisits\n",
    "print(\"TotalVisits - Value Counts\")\n",
    "print(\"----------------------------------------\")\n",
    "df_leads.TotalVisits.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads['TotalVisits'].fillna(df_leads['TotalVisits'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Views Per Visit\n",
    "print(\"Page Views Per Visit - Value Counts\")\n",
    "print(\"----------------------------------------\")\n",
    "df_leads.TotalVisits.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Views Per Visit missing values to be imputed with mode\n",
    "\n",
    "df_leads['Page Views Per Visit'].fillna(df_leads['Page Views Per Visit'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re Checking the percentage of null values after handling categorical and numerical columns\n",
    "\n",
    "round(((df_leads.isnull().sum()/df_leads.shape[0])*100),2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Notable Activity\n",
    "print(\"Last Notable Activity\")\n",
    "print(\"----------------------------------------\")\n",
    "100*df_leads['Last Notable Activity'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for columns with one unique value, count and freq is same\n",
    "\n",
    "df_leads.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns with one unique value whose count and frequency are same, we will drop these columns\n",
    "cols_to_drop = ['Magazine','Receive More Updates About Our Courses',\n",
    "                    'Update me on Supply Chain Content',\n",
    "                    'Get updates on DM Content',\n",
    "                    'I agree to pay the amount through cheque']\n",
    "\n",
    "print(\"Before Dropping Columns\",df_leads.shape)\n",
    "df_leads.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "print(\"After Dropping Columns\",df_leads.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Columns\n",
    "print(\"Before Dropping Columns\",df_leads.shape)\n",
    "df_leads.drop(['Prospect ID','Lead Number','Last Notable Activity'],axis=1,inplace=True)\n",
    "print(\"After Dropping Columns\",df_leads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of missing values in each row,output in descending order so high value will come on top\n",
    "\n",
    "100*(df_leads.isna().mean(axis=1)).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting countplot for object dtype and histogram for number to get data distribution\n",
    "categorical_col = df_leads.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "plt.figure(figsize=(12,40))\n",
    "\n",
    "plt.subplots_adjust(wspace=.2,hspace=2)\n",
    "for i in enumerate(categorical_col):\n",
    "    plt.subplot(8,2, i[0]+1)\n",
    "    ax=sns.countplot(x=i[1],data=df_leads) \n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical columns with highly skewed data\n",
    "\n",
    "print(\"Before Drop: \",df_leads.shape)\n",
    "df_leads.drop(['Do Not Call','Search','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement','Through Recommendations'],axis=1,inplace=True)\n",
    "print(\"After Drop: \",df_leads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_Outliers(data,columnList):\n",
    "\n",
    "    plt.figure(figsize=[22,11])\n",
    "    plt.subplots_adjust(wspace=0.4,hspace=0.5)\n",
    "\n",
    "    for i,j in enumerate(columnList):\n",
    "        plt.subplot(2,2,i+1)\n",
    "\n",
    "        sns.boxplot(y=data[j])     # y = df_leads[j] to make plot verticle\n",
    "\n",
    "        plt.suptitle(\"\\nChecking Outliers using Boxplot\",fontsize=20,color=\"green\")\n",
    "        plt.ylabel(None)\n",
    "        plt.title(j,fontsize=15,color='brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers for numerical variables other than target variable \n",
    "num_cols = [\"TotalVisits\",\"Page Views Per Visit\",\"Total Time Spent on Website\"]\n",
    "\n",
    "# UDF \n",
    "Check_Outliers(df_leads,num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before outlier treatment\n",
    "df_leads.describe(percentiles=[.10,.25,.50,.75,.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining UDF to treat outliers via capping and flooring\n",
    "\n",
    "def Outlier_treatment(df,columnList):\n",
    "    for i in columnList:\n",
    "        q1 = df[i].describe()[\"25%\"]\n",
    "        q3 = df[i].describe()[\"75%\"]\n",
    "        IQR = q3 - q1\n",
    "\n",
    "        upper_bound = q3 + 1.5*IQR\n",
    "        lower_bound = q1 - 1.5*IQR\n",
    "\n",
    "        # capping upper_bound\n",
    "        df[i] = np.where(df[i] > upper_bound, upper_bound,df[i])\n",
    "\n",
    "        # flooring lower_bound\n",
    "        df[i] = np.where(df[i] < lower_bound, lower_bound,df[i])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers for numerical variables other than target variable \n",
    "capping_cols = [\"TotalVisits\",\"Page Views Per Visit\"]\n",
    "\n",
    "# UDF \n",
    "Outlier_treatment(df_leads,capping_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after outlier treatment detailed percentile values\n",
    "df_leads.describe(percentiles=[.10,.25,.50,.75,.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical Variables \n",
    "\n",
    "columnsList_cat = [\"Lead Origin\",\"Lead Source\",\"Do Not Email\",\"Last Activity\",\"Specialization\",\n",
    "                  \"What is your current occupation\",\"A free copy of Mastering The Interview\"]\n",
    "\n",
    "for i in columnsList_cat:\n",
    "        perc=100*df_leads[i].value_counts(normalize=True)\n",
    "        print(\"value_counts % for :\",i,\"\\n\")\n",
    "        print(perc,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping low frequency value levels to Others\n",
    "df_leads['Lead Source'] = df_leads['Lead Source'].replace([\"bing\",\"Click2call\",\"Press_Release\",\n",
    "                                                           \"Social Media\",\"Live Chat\",\"youtubechannel\",\n",
    "                                                           \"testone\",\"Pay per Click Ads\",\"welearnblog_Home\",\n",
    "                                                           \"WeLearn\",\"blog\",\"NC_EDM\"],\"Others\")\n",
    "\n",
    "# Changing google to Google\n",
    "df_leads['Lead Source'] = df_leads['Lead Source'].replace(\"google\",\"Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts percentage after replace\n",
    "df_leads[\"Lead Source\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping low frequency value levels to Others \n",
    "df_leads['Last Activity'] = df_leads['Last Activity'].replace(['Unreachable','Unsubscribed',\n",
    "                                                               'Had a Phone Conversation', \n",
    "                                                               'Approached upfront',\n",
    "                                                               'View in browser link Clicked',       \n",
    "                                                               'Email Marked Spam',                  \n",
    "                                                               'Email Received','Visited Booth in Tradeshow',\n",
    "                                                               'Resubscribed to emails'],'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts percentage after replace\n",
    "df_leads['Last Activity'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column name to \"Free_copy\" from \"A free copy of Mastering The Interview\"\n",
    "df_leads.rename(columns={'A free copy of Mastering The Interview': 'Free_copy'}, inplace=True)\n",
    "\n",
    "# Renaming column name to \"Current_occupation\" from \"What is your current occupationA free copy of Mastering The Interview\"\n",
    "df_leads.rename(columns={'What is your current occupation': 'Current_occupation'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping binary categorical variables (Yes/No to 1/0) \n",
    "df_leads['Do Not Email'] = df_leads['Do Not Email'].apply(lambda x: 1 if x =='Yes' else 0)\n",
    "\n",
    "df_leads['Free_copy'] = df_leads['Free_copy'].apply(lambda x: 1 if x =='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084125\">Step 4: Data Analysis (EDA)</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ploting the results on bar plot\n",
    "\n",
    "ax=(100*df_leads[\"Converted\"].value_counts(normalize=True)).plot.bar(color=[\"Green\",\"Red\"],alpha=0.4)\n",
    "\n",
    "# Adding and formatting title\n",
    "plt.title(\"Leads Converted\\n\", fontdict={'fontsize': 16, 'fontweight' : 12, 'color' : 'Green'})\n",
    "\n",
    "\n",
    "# Labeling Axes\n",
    "plt.xlabel('Converted', fontdict={'fontsize': 12, 'fontweight' : 20, 'color' : 'Brown'})\n",
    "plt.ylabel(\"Percentage Count\", fontdict={'fontsize': 12, 'fontweight' : 20, 'color' : 'Brown'})\n",
    "\n",
    "# modification ticks y axis\n",
    "ticks=np.arange(0,101,20)\n",
    "labels=[\"{:.0f}%\".format(i) for i in ticks] \n",
    "plt.yticks(ticks,labels)\n",
    "\n",
    "#xticks\n",
    "plt.xticks([0,1],[\"No\",\"Yes\"])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.1f}%'.format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                  ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ratio of Data Imbalance\n",
    "ratio=(df_leads[\"Converted\"].value_counts(normalize=True).loc[0])/(df_leads[\"Converted\"].value_counts(normalize=True).loc[1])\n",
    "\n",
    "print(\"Data Imbalance Ratio : {:.2f} : {}\".format(ratio,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of categorical columns\n",
    "cat_cols = [\"Lead Origin\",\"Current_occupation\",\"Do Not Email\",\n",
    "            \"Free_copy\",\"Lead Source\",\"Last Activity\",\"Specialization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot of columns with its value_counts percentage as annotation\n",
    "for i in cat_cols[:4]:\n",
    "    \n",
    "    plt.figure(figsize=[10,5])\n",
    "    plt.title(\"Count plot of {}\".format(i),color=\"green\")\n",
    "    ax=sns.countplot(x=i,data=df_leads)\n",
    "    total=len(df_leads[i])\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        text = '{:.1f}%'.format(100*p.get_height()/total)\n",
    "        x = p.get_x() + p.get_width() / 2.\n",
    "        y = p.get_height()\n",
    "        \n",
    "        ax.annotate(text, (x,y), ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot for remaining columns from cat_cols (Did separate to rotate xticks 90* so labels doesnt become messy)\n",
    "for i in cat_cols[4:]:\n",
    "    \n",
    "    plt.figure(figsize=[10,5])\n",
    "    plt.title(\"Count plot of {}\".format(i),color=\"green\")\n",
    "    ax=sns.countplot(x=i,data=df_leads)\n",
    "    total=len(df_leads[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    \n",
    "    if i!=\"Specialization\":        # (not doing for Specialization xtick labels will be messy)\n",
    "        for p in ax.patches:\n",
    "            text = '{:.1f}%'.format(100*p.get_height()/total)\n",
    "            x = p.get_x() + p.get_width() / 2.\n",
    "            y = p.get_height()\n",
    "\n",
    "            ax.annotate(text, (x,y), ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bivariate_cat(df, variable_name, Target=\"Converted\"):\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.suptitle(f\"{variable_name} Countplot vs Lead Conversion Rates\", color=\"Brown\", fontsize=18)\n",
    "    \n",
    "    # 1st plot in subplot\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(f\"Distribution of {variable_name}\", color=\"blue\")\n",
    "    ax = sns.countplot(x=variable_name, hue=Target, data=df, palette=\"prism_r\", alpha=0.46)\n",
    "    \n",
    "    total = len(df[variable_name])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend([\"No\", \"Yes\"], title=\"Converted\")\n",
    "    \n",
    "    # Annotation for 1st plot        \n",
    "    for p in ax.patches:\n",
    "        text = f'{100*p.get_height()/total:.1f}%'\n",
    "        x = p.get_x() + p.get_width() / 2.\n",
    "        y = p.get_height()\n",
    "        ax.annotate(text, (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "    \n",
    "    # 2nd plot\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(f\"Lead Conversion Rate of {variable_name}\", color=\"green\", fontsize=12)\n",
    "    ax = sns.countplot(x=variable_name, hue=Target, data=df, palette=\"BuGn\", alpha=0.85)\n",
    "    \n",
    "    # Modifications\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Count\", color='brown')\n",
    "    plt.xlabel(variable_name)\n",
    "    plt.legend(labels=[\"Not Converted\", \"Converted\"], title=\"Lead Conversion Rate\")\n",
    "    \n",
    "    # Annotation for 2nd plot\n",
    "    all_heights = [[p.get_height() for p in bars] for bars in ax.containers]\n",
    "    \n",
    "    # Ensure all bars have the same length of heights\n",
    "    max_length = max(len(x) for x in all_heights)\n",
    "    for bars in ax.containers:\n",
    "        for i, p in enumerate(bars):\n",
    "            if i >= max_length:\n",
    "                continue\n",
    "            total = sum(xgroup[i] for xgroup in all_heights if i < len(xgroup))\n",
    "            if total > 0:\n",
    "                percentage = f'{(100 * p.get_height() / total):.1f}%'\n",
    "                ax.annotate(percentage, (p.get_x() + p.get_width() / 2, p.get_height()), size=11, ha='center', va='bottom')\n",
    "\n",
    "# Bivariate Analysis for all these variables using loop and UDF\n",
    "cat_cols = [\"Lead Origin\", \"Current_occupation\", \"Do Not Email\",\n",
    "            \"Lead Source\", \"Last Activity\", \"Specialization\", \"Free_copy\"]\n",
    "\n",
    "for i in cat_cols:\n",
    "    Bivariate_cat(df_leads, variable_name=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "sns.pairplot(data=df_leads,vars=num_cols,hue=\"Converted\")                                  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols =[\"Converted\",'TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap to show correlation between numerical variables\n",
    "sns.heatmap(data=df_leads[num_cols].corr(),cmap=\"Blues\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot with Converted as hue\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(y = 'TotalVisits', x = 'Converted', data = df_leads)\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(y = 'Page Views Per Visit', x = 'Converted', data = df_leads)\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(y = 'Total Time Spent on Website', x = 'Converted', data = df_leads)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084125\">Step 5: Data Preparation</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a dummy variable for some of the categorical variables and dropping the first one.\n",
    "dummy = pd.get_dummies(df_leads[[\"Lead Origin\",\"Lead Source\",\"Last Activity\",\"Specialization\",\"Current_occupation\"]], drop_first=True)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df_leads = pd.concat([df_leads, dummy], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created dummies for the below variables, so we can drop them\n",
    "\n",
    "df_leads = df_leads.drop([\"Lead Origin\", \"Lead Source\", \"Last Activity\", \"Specialization\", \"Current_occupation\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 6: Test-Train Split </span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting predictor variables to X\n",
    "X = df_leads.drop('Converted', axis=1)\n",
    "\n",
    "# Putting Target variables to y\n",
    "y = df_leads[\"Converted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train:\", X_train.shape,\"\\ny_train:\",y_train.shape)\n",
    "print(\"X_test:\", X_test.shape,\"\\ny_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 7: Feature Scaling </span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "num_cols=X_train.select_dtypes(include=['int64','float64']).columns\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCR = (sum(df_leads['Converted'])/len(df_leads['Converted'].index))*100\n",
    "LCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))        \n",
    "sns.heatmap(df_leads.corr(),linewidths=0.01,cmap=\"Blues\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))        \n",
    "sns.heatmap(df_leads[[\"Lead Source_Facebook\",\"Lead Origin_Lead Import\",\"Lead Origin_Lead Add Form\",\"Lead Source_Reference\"]].corr(),linewidths=0.01,cmap=\"Blues\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['Lead Origin_Lead Import', 'Lead Origin_Lead Add Form'], axis=1)\n",
    "X_train = X_train.drop(['Lead Origin_Lead Import', 'Lead Origin_Lead Add Form'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084126\">Step 8: Model Building</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, n_features_to_select=15)            \n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15=pd.DataFrame()\n",
    "top15['features']=X_train.columns\n",
    "top15['Feature Chosen'] = rfe.support_\n",
    "top15['Ranking']=rfe.ranking_\n",
    "top15.sort_values(by='Ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which are selected by RFE\n",
    "rfe_col = X_train.columns[rfe.support_]\n",
    "rfe_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which are not selected by RFE\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vif(model_df):\n",
    "    X = pd.DataFrame()\n",
    "    X['Features'] = model_df.columns\n",
    "    X['VIF'] = [variance_inflation_factor(model_df.values, i) for i in range(model_df.shape[1])]\n",
    "    X['VIF'] = round(X['VIF'], 2)\n",
    "    X = X.sort_values(by='VIF', ascending=False)\n",
    "    X = X.reset_index(drop=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_rfe.dtypes)\n",
    "print(y_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integer type (0 and 1)\n",
    "X_train_rfe = X_train_rfe.astype(int)\n",
    "\n",
    "# Ensure y_train is numeric\n",
    "y_train = y_train.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and convert data types if necessary\n",
    "X_train_rfe = pd.get_dummies(X_train_rfe, drop_first=True)\n",
    "y_train = y_train.astype(float)  # Ensure target is numeric\n",
    "\n",
    "# Adding a constant variable\n",
    "X_train_sm1 = sm.add_constant(X_train_rfe)\n",
    "\n",
    "# Create a fitted model\n",
    "logm1 = sm.GLM(y_train, X_train_sm1, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Display model parameters\n",
    "print(logm1.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(logm1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe=X_train_rfe.drop(\"Lead Source_Facebook\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant variable \n",
    "X_train_sm2 = sm.add_constant(X_train_rfe)\n",
    "\n",
    "# Create a fitted model\n",
    "logm2 = sm.GLM(y_train,X_train_sm2,family = sm.families.Binomial()).fit()  \n",
    "\n",
    "logm2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logm2.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train_rfe.drop(\"Lead Source_Others\",axis=1)\n",
    "X_train_sm3 = sm.add_constant(X_train_rfe)\n",
    "\n",
    "# Create a fitted model\n",
    "logm3 = sm.GLM(y_train,X_train_sm3,family = sm.families.Binomial()).fit()  \n",
    "\n",
    "logm3.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logm3.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vif(X_train_rfe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:#084125\">Step 9: Model Evaluation</span></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = logm3.predict(X_train_sm3)           # giving prob. of getting 1\n",
    "\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a dataframe with the actual churn flag and the predicted probabilities\n",
    "\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "y_train_pred_final['Prospect ID'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Predicted'] = y_train_pred_final[\"Converted_Prob\"].map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix  (Actual / predicted)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Predicted\"])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(metrics.accuracy_score(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Predicted\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sensitivity :\",TP / float(TP+FN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Specificity :\",TN / float(TN+FP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False Positive rate: \",FP/ float(TN+FP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to draw ROC curve \n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Converted_Prob\"], drop_intermediate = False )\n",
    "draw_roc(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Converted_Prob\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final['Converted_Prob'].map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final[\"Converted\"], y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Check the range of probabilities\n",
    "prob_min = cutoff_df['prob'].min()\n",
    "prob_max = cutoff_df['prob'].max()\n",
    "\n",
    "# Finding the intersection points of the sensitivity and accuracy curves\n",
    "sensi_interp = interp1d(cutoff_df['prob'], cutoff_df['sensi'], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "acc_interp = interp1d(cutoff_df['prob'], cutoff_df['accuracy'], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "# Ensure initial guess is within bounds\n",
    "initial_guess = 0.5\n",
    "if initial_guess < prob_min:\n",
    "    initial_guess = prob_min\n",
    "elif initial_guess > prob_max:\n",
    "    initial_guess = prob_max\n",
    "\n",
    "intersection_1 = np.round(float(fsolve(lambda x: sensi_interp(x) - acc_interp(x), initial_guess)), 3)\n",
    "\n",
    "# Finding the intersection points of the specificity and accuracy curves\n",
    "speci_interp = interp1d(cutoff_df['prob'], cutoff_df['speci'], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "intersection_2 = np.round(float(fsolve(lambda x: speci_interp(x) - acc_interp(x), initial_guess)), 3)\n",
    "\n",
    "# Calculate the average of the two intersection points\n",
    "intersection_x = (intersection_1 + intersection_2) / 2\n",
    "\n",
    "# Interpolate the accuracy, sensitivity, and specificity at the intersection point\n",
    "accuracy_at_intersection = np.round(float(acc_interp(intersection_x)), 2)\n",
    "sensitivity_at_intersection = np.round(float(sensi_interp(intersection_x)), 2)\n",
    "specificity_at_intersection = np.round(float(speci_interp(intersection_x)), 2)\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the lines for accuracy, sensitivity, and specificity\n",
    "fig.add_trace(go.Scatter(x=cutoff_df['prob'], y=cutoff_df['accuracy'], mode='lines', name='Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=cutoff_df['prob'], y=cutoff_df['sensi'], mode='lines', name='Sensitivity'))\n",
    "fig.add_trace(go.Scatter(x=cutoff_df['prob'], y=cutoff_df['speci'], mode='lines', name='Specificity'))\n",
    "\n",
    "# Add vertical and horizontal lines at the intersection point\n",
    "fig.add_shape(type=\"line\",\n",
    "              x0=intersection_x, y0=0, x1=intersection_x, y1=accuracy_at_intersection,\n",
    "              line=dict(color=\"Grey\", width=1, dash=\"dash\"))\n",
    "\n",
    "fig.add_shape(type=\"line\",\n",
    "              x0=0, y0=accuracy_at_intersection, x1=intersection_x, y1=accuracy_at_intersection,\n",
    "              line=dict(color=\"Grey\", width=1, dash=\"dash\"))\n",
    "\n",
    "# Annotate the intersection point\n",
    "fig.add_annotation(x=intersection_x, y=accuracy_at_intersection,\n",
    "                   text=f'({intersection_x} , {accuracy_at_intersection})',\n",
    "                   showarrow=True, arrowhead=1,\n",
    "                   ax=0, ay=-40, xanchor='left', yanchor='bottom')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Accuracy, Sensitivity, and Specificity Curves\",\n",
    "    xaxis_title=\"Probability Cutoff\",\n",
    "    yaxis_title=\"Value\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final['Converted_Prob'].map( lambda x: 1 if x > 0.345 else 0)\n",
    "\n",
    "# deleting the unwanted columns from dataframe\n",
    "y_train_pred_final.drop([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,\"Predicted\"],axis = 1, inplace = True) \n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final[\"Converted\"], y_train_pred_final[\"final_predicted\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_all_metrics(confusion_matrix):\n",
    "    TN =confusion_matrix[0,0]\n",
    "    TP =confusion_matrix[1,1]\n",
    "    FP =confusion_matrix[0,1]\n",
    "    FN =confusion_matrix[1,0]\n",
    "    \n",
    "    accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "    sensi = TP/(TP+FN)\n",
    "    speci = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    TPR = TP/(TP + FN)\n",
    "    TNR = TN/(TN + FP)\n",
    "    \n",
    "    #Calculate false postive rate - predicting conversion when customer does not have converted\n",
    "    FPR = FP/(FP + TN)     \n",
    "    FNR = FN/(FN +TP)\n",
    "    \n",
    "    print (\"True Negative                    : \", TN)\n",
    "    print (\"True Positive                    : \", TP)\n",
    "    print (\"False Negative                   : \", FN)\n",
    "    print (\"False Positve                    : \", FP) \n",
    "    \n",
    "    print (\"Model Accuracy                   : \", round(accuracy,4))\n",
    "    print (\"Model Sensitivity                : \", round(sensi,4))\n",
    "    print (\"Model Specificity                : \", round(speci,4))\n",
    "    print (\"Model Precision                  : \", round(precision,4))\n",
    "    print (\"Model Recall                     : \", round(recall,4))\n",
    "    print (\"Model True Positive Rate (TPR)   : \", round(TPR,4))\n",
    "    print (\"Model False Positive Rate (FPR)  : \", round(FPR,4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion metrics for 'y_train_pred_final' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_train_pred_final['Converted'], y_train_pred_final['final_predicted'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating precision-recall tradeoff curve\n",
    "y_train_pred_final['Converted'], y_train_pred_final['final_predicted']\n",
    "p, r, thresholds = precision_recall_curve(y_train_pred_final['Converted'], y_train_pred_final['Converted_Prob'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall tradeoff curve\n",
    "plt.plot(thresholds, p[:-1], \"g-\", label=\"Precision\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\", label=\"Recall\")\n",
    "\n",
    "# add legend and axis labels\n",
    "\n",
    "plt.axvline(x=0.41, color='teal',linewidth = 0.55, linestyle='--')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying df to test model evaluation with precision recall threshold of 0.41\n",
    "y_train_precision_recall = y_train_pred_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning a feature for 0.41 cutoff from precision recall curve to see which one is best view (sensi-speci or precision-recall)\n",
    "y_train_precision_recall['precision_recall_prediction'] = y_train_precision_recall['Converted_Prob'].map( lambda x: 1 if x > 0.41 else 0)\n",
    "y_train_precision_recall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion metrics for 'y_train_precision_recall' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_train_precision_recall['Converted'], y_train_precision_recall['precision_recall_prediction'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add Lead Score \n",
    "\n",
    "y_train_pred_final['Lead_Score'] = y_train_pred_final['Converted_Prob'].map( lambda x: round(x*100))\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=X_test.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "# scaling columns\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "X_test = X_test[rfe_col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding contant value\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "X_test_sm.drop([\"Lead Source_Facebook\",\"Lead Source_Others\",\"Current_occupation_Housewife\",\"Specialization_Others\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = logm3.predict(X_test_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 columns\n",
    "y_test_pred[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to dataframe of predicted probability\n",
    "y_test_pred = pd.DataFrame(y_test_pred)\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})\n",
    "\n",
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex(['Prospect ID','Converted','Converted_Prob'], axis=1)\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion metrics for 'y_train_pred_final' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final['final_predicted'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets add Lead Score \n",
    "\n",
    "y_pred_final['Lead_Score'] = y_pred_final['Converted_Prob'].map( lambda x: round(x*100))\n",
    "y_pred_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
